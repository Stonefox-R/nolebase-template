>神经网络的本质就是极端的信息压缩，将数字信息压缩到人类的语义空间中
## 基础优化算法
我们应该怎样对神经网络进行优化是一个十分精细的工程，这个过程通常使用**梯度下降法**来计算。其中有几个重要的可调参数需要注意
1. 小批量尺寸大小（batch size）
由于训练数据集通常很大，如果要对整个数据集进行梯度计算花费的时间可能长达数小时，为了缩小计算代价，我们使用在训练数据集中采集指定数据样本大小的方法来降低计算代价。**过大**计算代价降低不明显，**过小**导致最后准确率低
2. 学习率（learn rate）
每次调整时的步长（我的理解是向量的模长）可以参考下图
![[Pasted image 20240630142137.png]]
**过大**会持续震荡，**过小**会加大计算难度
![[Pasted image 20240630142307.png]]

## [线性回归问题](/notebooks/pytorch/chapter_linear-networks/linear-regression-scratch.ipynb)
首先是数据生成函数：
```python
def synthetic_data(w, b, num_examples):  #@save
    """生成y=Xw+b+噪声"""
    X = torch.normal(0, 1, (num_examples, len(w)))
    y = torch.matmul(X, w) + b
    y += torch.normal(0, 0.01, y.shape)
    return X, y.reshape((-1, 1))
```
课程中调用如下：
```python
true_w = torch.tensor([2, -3.4])
true_b = 4.2
features, labels = synthetic_data(true_w, true_b, 1000)
```
看着有点懵，特别是看到下面的可视化结果
```python
d2l.set_figsize()
d2l.plt.scatter(features[:,1].detach().numpy(), labels.detach().numpy(), 1);
```
![[Pasted image 20240702093852.png]]
我在想为什么`y`会和`features[:,1]`的值呈线性关系，后来才发现这里是钻了牛角尖。只是因为`y`的值的运算方法满足线性关系。

## softmax回归
>回归后输出不同类别概率
### 网络结构
同时被视作全连接层
![[Pasted image 20240702191212.png]]
详情请看DL_learn/softmax_scratch.py

## 感知机
>二分类问题
![[Pasted image 20240702191457.png]]
### 多层感知机
>因为感知机无法解决xor问题，于是出现了多层感知机
>其实和softMax的最大区别就是中间的隐藏层

![[Pasted image 20240712142406.png]]
中间的蓝色层与黄色层可以称为隐藏层
![[Pasted image 20240712142628.png]]
**所有的网络对于pytorch来说都是网络结构的区别，叫法不同但用pytorch实现起来还是比较一致的**

## 模型的选择
几个基本术语
* 训练误差：模型在训练模型上的误差
* 泛化误差：模型在新数据上的误差
* 验证数据集：用来评估模型的好坏，例如拿出50%的训练数据 **不要和训练数据混合**
* 测试数据集：最终测试的数据集，只用一次

### k-则交叉验证
>将数据分割k块，某一块作为验证数据集，其余的为训练数据集。

![[Pasted image 20240713132923.png]]

特征：在非大数据集上使用

### 过拟合与欠拟合
![[Pasted image 20240713133524.png]]
![[Pasted image 20240713133834.png]]
>**模型容量**指的是拟合各种函数的能力，低容量难以拟合训练数据，高容量可以记住所有数据

在**给定**模型种类时，模型容量大小取决于两个主要因素
* 参数个数
* 参数值的范围

![[Pasted image 20240713133653.png]]
***重要：模型容量需要匹配数据复杂度，在实践中一般考观察和经验确定***

## 权重衰退
### 均方范数做硬性约束
![[Pasted image 20240714135317.png]]
### 柔性限制
![[Pasted image 20240714135344.png]]

**那么如何衰退，以及为什么会衰退呢？**
![[Pasted image 20240714140012.png]]
通过观察上图的例子我们不难发现，其权重是随着时间的推移而不断变小的。
在`pytorch`中，lamda为各优化函数的weight decay参数

## 丢弃法（drop out）
>学界认为也是一种正则化限制
![[Pasted image 20240714145444.png]]
![[Pasted image 20240714145507.png]]
本质上是随机屏蔽某些单元

## 数值稳定性
在层数较低的网络中不太存在数值稳定性的问题，but 当层数很多时会出现两种不同的问题

因为每一层的梯度计算都是一个前面层的累乘过程，所以激活函数的选择至关重要
### 1. 梯度爆炸
![[Pasted image 20240714155454.png]]
在使用`ReLu`作为激活函数时会导致上一层梯度保留，此时下一层进行相乘运算会继续扩大梯度。经过比较深的几层后会梯度爆炸。
![[Pasted image 20240714155912.png]]
#### 可能导致的问题
* 超出浮点值域
>通常选择 float16 作为数据类型，因为这是精度和速度的综合选择。但梯度爆炸后会导致溢出
* 对学习率敏感
	* 如果学习率过大-> 大参数值-> 更大的梯度
	* 如果学习率太小 -> 训练无进展

### 2. 梯度消失
![[Pasted image 20240714155502.png]]
当使用`Sigmoid`作为激活函数并且神经网络层数过多时会导致梯度消失
![[Pasted image 20240714160112.png]]

### 让训练更稳定
合理的权重初始值与激活函数选取
![[Pasted image 20240714162119.png]]

## **房屋数据**
让我们来看看第一个上手案例吧！！

## PyTorch 神经网络基础
pytorch/chapter_deep-learning-computation/ 看看这里，是小土堆的深入，主要在**参数管理**与**自定义层**有些深入的教学

## [使用GPU](http://localhost:8888/notebooks/pytorch/chapter_deep-learning-computation/use-gpu.ipynb)

Moudle只能使用`to(device)` ，`tensor.cuda`

## 卷积

### 多输入通道
例如RGB图像，除了宽和高还有一个RGB通道信息
![[Pasted image 20240723152812.png]]
![[Pasted image 20240723152822.png]]
为了减少信息的丢失，我们将色彩通道也引入卷积。具体操作方法如下
![[Pasted image 20240723152955.png]]
#### 多输出通道
![[Pasted image 20240723153253.png]]
**为什么需要多通道的输入与输出？**
>每个输出通道都可以识别特定的模式，例如：
>![[Pasted image 20240723153620.png]]
>上面的例子输出了六通道，其在不同的通道都获取了不同的特征，而传入下一层后网络将会把这些特征做一个整合操作 从**猫眼睛+胡子+耳朵--->猫脸 / 猫腿猫+肚子--->猫body / 最后整合到识别猫**。这一过程也是神经网络一直所实现的信息提取，压缩

#### 多通道到底是怎么运算的？
在学习过程中看到了这么一张图![[c9ca3adc150b95576fba1c42cbbe625022e9dc58.png@690w_!web-note.webp]]
开始的时候误以为是把 每个输入chan分别和一个卷积核做运算后相加得出。最后发现是一个卷积核的三个通道输入通道分别和输入的三个chan做卷积运算输出。
#### 1x1卷积层
等同于一个全连接层，用以融合不同通道的信息
![[Pasted image 20240723161121.png]]
## 池化层(pooling)
>卷积层对边界识别十分敏感，为了降低各种噪音的扰动所以引入了池化层

* 特征：超参数和**卷积层**一致
* 作用：缓解卷积层位置敏感性
### 最大池化层
![[Pasted image 20240723202425.png]]
### 平均池化层

## LeNet

![[Pasted image 20240728102114.png]]

## AlexNet
>本质和Lenet一致，仅改动网络结构让他更深
![[Pasted image 20240827151118.png]]

## VGG
>如何更深更大？使用模块化的思想！

将AlexNet中的卷积组合为一个模块以方便多次堆叠出**更深**的网络结构。通过不同卷积块的个数以及参数衍生出变种。
本质就是==神经网络的封装==

## NIN
>使用了卷积层替代了全连接层
![[Pasted image 20240828115050.png]]
![[Pasted image 20240828114924.png]]
![[Pasted image 20240828114931.png]]

[模型参数计算](https://zhuanlan.zhihu.com/p/376925457)


## googleNet
>引入了inception块

![[Pasted image 20240828170957.png]]

## batchnorm(批量归一化)
>可以认为是在小批量中加入噪音控制复杂度。其固定了小批量中的均值与方差，之后学习出适合的便宜与缩放

其也是一个拥有参数的层，类似卷积层

![[Pasted image 20240830104451.png]]

* 没必要和丢弃法混合使用
* 加速收敛（可以提高学习率）
* 不改变模型精度

## resNet
>保证复杂模型不会比简单模型效果差


![[Pasted image 20240830112625.png]]
### 具体实现方法
![[Pasted image 20240830112940.png]]
* 可以训练很深的网络
* 对所有网络都产生了影响

### 真正的原理
![[Pasted image 20240902145344.png]]
从底层来说是加法求导法则再起作用，具体详细原理待之后补充

## 第二次竞赛
### LeNet结果
0.05% 不知道为什么结果跑出来这么差。感觉代码哪里写错了

### AlexNet
* 所有的分类问题都需要loos为`CrossEntropy`吗？
* 
## 单机多GPU
常用方案有：
* 数据并行：将小批量分成n块，每个GPU拿到完整参数计算某部分梯度
	* 优点：性能好
	* 使用场景：模型单卡能够计算时
	* 具体实现：n.dataParalle()
![[Pasted image 20240720104027.png]]
* 模型并行：串行推理
	* 用于超大模型

## 图片增广
>由于在最后的预测时输入的数据可能会存在意外情况（如照明条件不同，获取输入的设备差异等）导致模型准确性大大降低，所以在训练时我们会对数据集进行增广操作。本质是**预测可能的数据情况**

